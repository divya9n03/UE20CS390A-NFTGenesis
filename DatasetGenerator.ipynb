{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOtScLse0gizfioQ9PCHZ8p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/divya9n03/UE20CS390A-NFTGenesis/blob/main/DatasetGenerator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using OpenSea API to collect NFTs from the official website and storing said data into a Google Drive folder. This data will be specifically used to train the generator component of NFTGenesis. The NFT generator will take input an NFT and geenrate a full collection based on the input theme,color gradient, texture, object in focus, etc."
      ],
      "metadata": {
        "id": "MTJOis1qhCIM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PnRcLAGwd25D"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "import pandas as pd\n",
        "import requests\n",
        "import urllib.request\n",
        "api_key = \"418a8f412d6b4cf8bbb973cd48f046eb\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "warnings.filterwarnings('ignore')\n",
        "df = pd.DataFrame(columns=['id', 'token_id', 'num_sales', 'background_color', 'image_url', 'image_preview_url', 'image_thumbnail_url', 'image_original_url', 'animation_url', 'animation_original_url', 'name', 'description', 'external_link', 'asset_contract', 'permalink', 'collection', 'decimals', 'token_metadata', 'is_nsfw', 'owner', 'seaport_sell_orders', 'creator', 'traits', 'last_sale', 'top_bid', 'listing_date', 'supports_wyvern', 'rarity_data', 'transfer_fee', 'transfer_fee_payment_token'])"
      ],
      "metadata": {
        "id": "I2Dmk5OQfPpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>OpenSea API to fetch directly from the platform"
      ],
      "metadata": {
        "id": "HaaQTfQKgJpK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "offset=0\n",
        "k=0\n",
        "\n",
        "#fetching approximately 10000 NFTs\n",
        "for n in range(5000):\n",
        "  try:\n",
        "    if n!=0:\n",
        "      offset+=200\n",
        "    endpoint=\"https://api.opensea.io/api/v1/assets?offset=\"+str(offset)+\"&limit=200\"\n",
        "    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36','referrer':endpoint,\"X-API-KEY\": api_key}\n",
        "\n",
        "    # Make a GET request to the OpenSea API\n",
        "    response = requests.get(endpoint, headers=headers)\n",
        "    id_l=[]\n",
        "    token_id_l=[]\n",
        "\n",
        "    #response was successful (status code 200)\n",
        "    if response.status_code == 200:\n",
        "        # Parse the JSON data from the response\n",
        "        data = response.json()\n",
        "\n",
        "        for i in data['assets']:\n",
        "          if i['image_url']!=None:\n",
        "            df=df.append(i,ignore_index=True)\n",
        "            print(\"-\",end=\"\")\n",
        "            k+=1\n",
        "  except:\n",
        "    continue\n",
        "df.to_csv('/content/dataset.csv')\n",
        "print(\"\\n\",k,\"images have been written\")\n",
        "print(\"\\ndone writing to csv\")\n"
      ],
      "metadata": {
        "id": "mDoOho-IfSCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3> Storing fetched images in Dataset folder (GoogleDrive)"
      ],
      "metadata": {
        "id": "pGRHIK53gabc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#fetching column from above dataframe\n",
        "\n",
        "img_urls=df['image_url']\n",
        "k=0\n",
        "\n",
        "for i in img_urls:\n",
        "  try:\n",
        "    file_name= \"/content/gdrive/MyDrive/capstone\"+\"/image\"+str(k)+\".jpg\"\n",
        "    urllib.request.urlretrieve(i, file_name)\n",
        "    print(\"-\",end=\"\")\n",
        "    k+=1\n",
        "  except:\n",
        "    continue\n",
        "print(k,\" images have been written to drive\")\n",
        "\n"
      ],
      "metadata": {
        "id": "8yRWuSPrfy2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>158878 images are added to dataset"
      ],
      "metadata": {
        "id": "2nYTWt41goos"
      }
    }
  ]
}